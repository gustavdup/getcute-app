#!/usr/bin/env python3
"""
Log viewer and analyzer for the WhatsApp bot.
This script helps analyze the detailed logs generated by the message processing pipeline.
"""
import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

def parse_log_line(line: str) -> Dict[str, Any]:
    """Parse a log line and extract structured information."""
    # Pattern for log lines: timestamp - logger - level - [file:line] - message
    pattern = r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3}) - (.+?) - (\w+) - \[(.+?)\] - (.+)'
    match = re.match(pattern, line)
    
    if not match:
        return {"raw": line, "parsed": False}
    
    timestamp_str, logger_name, level, location, message = match.groups()
    
    # Try to parse JSON in the message
    json_data = None
    if message.startswith(('STAGE_', 'SUCCESS_STAGE_', 'ERROR_STAGE_', 'AI_CLASSIFICATION', 'DB_', 'MEDIA_')):
        json_start = message.find(': {')
        if json_start != -1:
            json_str = message[json_start + 2:]
            try:
                json_data = json.loads(json_str)
            except json.JSONDecodeError:
                pass
    
    return {
        "timestamp": timestamp_str,
        "logger": logger_name,
        "level": level,
        "location": location,
        "message": message,
        "json_data": json_data,
        "parsed": True
    }

def analyze_message_flow(log_entries: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze the flow of a single message through the system."""
    
    # Group entries by message_id
    message_flows = {}
    
    for entry in log_entries:
        if entry.get("json_data") and "message_id" in entry["json_data"]:
            msg_id = entry["json_data"]["message_id"]
            if msg_id not in message_flows:
                message_flows[msg_id] = []
            message_flows[msg_id].append(entry)
    
    return message_flows

def print_message_flow_summary(message_id: str, entries: List[Dict[str, Any]]):
    """Print a summary of a message's flow through the system."""
    print(f"\n{'='*60}")
    print(f"MESSAGE FLOW: {message_id}")
    print(f"{'='*60}")
    
    stages = []
    errors = []
    
    for entry in entries:
        if not entry.get("json_data"):
            continue
            
        json_data = entry["json_data"]
        stage = json_data.get("stage", "unknown")
        timestamp = json_data.get("timestamp", entry["timestamp"])
        
        if entry["level"] == "ERROR":
            errors.append({
                "stage": stage,
                "timestamp": timestamp,
                "error": json_data.get("error_message", json_data.get("error", "Unknown error")),
                "details": json_data
            })
        else:
            stages.append({
                "stage": stage,
                "timestamp": timestamp,
                "status": json_data.get("status", "processing"),
                "details": json_data
            })
    
    # Print stages
    print(f"\nStages completed ({len(stages)}):")
    for i, stage in enumerate(stages, 1):
        status_icon = "✅" if stage["status"] == "SUCCESS" else "🔄"
        print(f"  {i:2d}. {status_icon} {stage['stage']} ({stage['timestamp']})")
        
        # Print key details
        if stage["details"].get("classified_as"):
            print(f"      └─ Classified as: {stage['details']['classified_as']}")
        if stage["details"].get("result_summary"):
            print(f"      └─ Result: {stage['details']['result_summary']}")
        if stage["details"].get("file_info") and isinstance(stage["details"]["file_info"], dict):
            file_info = stage["details"]["file_info"]
            if file_info.get("size_bytes"):
                print(f"      └─ File size: {file_info['size_bytes']} bytes")
    
    # Print errors
    if errors:
        print(f"\nErrors encountered ({len(errors)}):")
        for i, error in enumerate(errors, 1):
            print(f"  {i:2d}. ❌ {error['stage']} ({error['timestamp']})")
            print(f"      └─ Error: {error['error']}")
    
    # Extract final content info
    first_entry = next((e for e in entries if e.get("json_data", {}).get("stage") == "MESSAGE_RECEIVED"), None)
    if first_entry:
        content = first_entry["json_data"].get("content_preview", "")
        msg_type = first_entry["json_data"].get("message_type", "unknown")
        print(f"\nMessage content: \"{content}\" (type: {msg_type})")
    
    print(f"\nTotal processing time: {len(entries)} log entries")

def main():
    """Main function to analyze the logs."""
    
    log_file = Path("logs/message_processing.log")
    
    if not log_file.exists():
        print("❌ No message processing log found. Make sure to run the bot or test script first.")
        return
    
    print("📊 WhatsApp Bot Message Processing Log Analyzer")
    print("=" * 60)
    
    # Read and parse log file
    with open(log_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    print(f"📄 Parsing {len(lines)} log lines...")
    
    log_entries = []
    for line in lines:
        parsed = parse_log_line(line.strip())
        if parsed["parsed"]:
            log_entries.append(parsed)
    
    print(f"✅ Parsed {len(log_entries)} structured log entries")
    
    # Analyze message flows
    message_flows = analyze_message_flow(log_entries)
    
    print(f"📨 Found {len(message_flows)} unique message flows")
    
    # Print summary for each message
    for message_id, entries in message_flows.items():
        print_message_flow_summary(message_id, entries)
    
    # Print overall statistics
    print(f"\n{'='*60}")
    print("OVERALL STATISTICS")
    print(f"{'='*60}")
    
    error_count = len([e for e in log_entries if e["level"] == "ERROR"])
    info_count = len([e for e in log_entries if e["level"] == "INFO"])
    
    print(f"Total log entries: {len(log_entries)}")
    print(f"Info messages: {info_count}")
    print(f"Error messages: {error_count}")
    print(f"Success rate: {((len(log_entries) - error_count) / len(log_entries) * 100):.1f}%")
    
    # Check specific issues
    issues = []
    for entry in log_entries:
        if entry["level"] == "ERROR" and entry.get("json_data"):
            json_data = entry["json_data"]
            stage = json_data.get("stage", "unknown")
            error = json_data.get("error_message", json_data.get("error", ""))
            
            if "JSON serializable" in error:
                issues.append("🐛 JSON serialization issue in logging")
            elif "not in allowed list" in error:
                issues.append("⚠️  Test phone number not in WhatsApp allowed list (expected)")
            elif "does not exist" in error:
                issues.append("⚠️  Test media ID doesn't exist (expected)")
            elif "User ID is None" in error:
                issues.append("🐛 User ID validation issue")
    
    if issues:
        print(f"\nIdentified Issues:")
        for issue in set(issues):  # Remove duplicates
            print(f"  • {issue}")
    
    print(f"\n📁 Full logs available at: {log_file.absolute()}")

if __name__ == "__main__":
    main()
